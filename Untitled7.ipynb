{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C://Users/feria/Documents/HAR-CNN-Keras-master/actitracker_raw.txt' does not exist: b'C://Users/feria/Documents/HAR-CNN-Keras-master/actitracker_raw.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-79f71e2373f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;31m# # # # # # # # #   reading the data   # # # # # # # # # #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m# Path of file #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C://Users/feria/Documents/HAR-CNN-Keras-master/actitracker_raw.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;31m# plotting a subset of the data to visualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mactivity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'activity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-79f71e2373f8>\u001b[0m in \u001b[0;36mreadData\u001b[1;34m(filePath)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# attributes of the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mcolumnNames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'activity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'x-axis'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'y-axis'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'z-axis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumnNames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# defining a function for feature normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C://Users/feria/Documents/HAR-CNN-Keras-master/actitracker_raw.txt' does not exist: b'C://Users/feria/Documents/HAR-CNN-Keras-master/actitracker_raw.txt'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep 27 14:34:20 2017\n",
    "This is a small project for CNN in KERAS.\n",
    "This file creates, trains and save a convolutional neural network for\n",
    "Human Acitivity Recognition. The data we used for this file is released and provided by\n",
    "Wireless Sensor Data Mining (WISDM) lab and can be found on this link.\n",
    "http://www.cis.fordham.edu/wisdm/dataset.php  \n",
    "Feel free to use this code and site this repositry if you use it for your reports or project.\n",
    "@author: Muhammad Shahnawaz\n",
    "\"\"\"\n",
    "# importing libraries and dependecies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "#from keras import backend as K\n",
    "from keras import optimizers\n",
    "#K.set_image_dim_ordering('th')\n",
    "# setting up a random seed for reproducibility\n",
    "random_seed = 611\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "# defining function for loading the dataset\n",
    "def readData(filePath):\n",
    "    # attributes of the dataset\n",
    "    columnNames = ['user_id','activity','timestamp','x-axis','y-axis','z-axis']\n",
    "    data = pd.read_csv(filePath,header = None, names=columnNames,na_values=';')\n",
    "    return data\n",
    "# defining a function for feature normalization\n",
    "# (feature - mean)/stdiv\n",
    "def featureNormalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset-mu)/sigma\n",
    "# defining the function to plot a single axis data\n",
    "def plotAxis(axis,x,y,title):\n",
    "    axis.plot(x,y)\n",
    "    axis.set_title(title)\n",
    "    axis.xaxis.set_visible(False)\n",
    "    axis.set_ylim([min(y)-np.std(y),max(y)+np.std(y)])\n",
    "    axis.set_xlim([min(x),max(x)])\n",
    "    axis.grid(True)\n",
    "# defining a function to plot the data for a given activity\n",
    "def plotActivity(activity,data):\n",
    "    fig,(ax0,ax1,ax2) = plt.subplots(nrows=3, figsize=(15,10),sharex=True)\n",
    "    plotAxis(ax0,data['timestamp'],data['x-axis'],'x-axis')\n",
    "    plotAxis(ax1,data['timestamp'],data['y-axis'],'y-axis')\n",
    "    plotAxis(ax2,data['timestamp'],data['z-axis'],'z-axis')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    fig.suptitle(activity)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "# defining a window function for segmentation purposes\n",
    "def windows(data,size):\n",
    "    start = 0\n",
    "    while start< data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start+= (size/2)\n",
    "# segmenting the time series\n",
    "def segment_signal(data, window_size = 90):\n",
    "    segments = np.empty((0,window_size,3))\n",
    "    labels= np.empty((0))\n",
    "    for (start, end) in windows(data['timestamp'],window_size):\n",
    "        x = data['x-axis'][start:end]\n",
    "        y = data['y-axis'][start:end]\n",
    "        z = data['z-axis'][start:end]\n",
    "        if(len(data['timestamp'][start:end])==window_size):\n",
    "            segments = np.vstack([segments,np.dstack([x,y,z])])\n",
    "            labels = np.append(labels,stats.mode(data['activity'][start:end])[0][0])\n",
    "    return segments, labels\n",
    "''' Main Code '''\n",
    "# # # # # # # # #   reading the data   # # # # # # # # # # \n",
    "# Path of file #\n",
    "dataset = readData('C://Users/feria/Documents/HAR-CNN-Keras-master/actitracker_raw.txt')\n",
    "# plotting a subset of the data to visualize\n",
    "for activity in np.unique(dataset['activity']):\n",
    "    subset = dataset[dataset['activity']==activity][:180]\n",
    "    plotActivity(activity,subset)\n",
    "# segmenting the signal in overlapping windows of 90 samples with 50% overlap\n",
    "segments, labels = segment_signal(dataset) \n",
    "#categorically defining the classes of the activities\n",
    "labels = np.asarray(pd.get_dummies(labels),dtype = np.int8)\n",
    "# defining parameters for the input and network layers\n",
    "# we are treating each segmeent or chunk as a 2D image (90 X 3)\n",
    "numOfRows = segments.shape[1]\n",
    "numOfColumns = segments.shape[2]\n",
    "numChannels = 1\n",
    "numFilters = 128 # number of filters in Conv2D layer\n",
    "# kernal size of the Conv2D layer\n",
    "kernalSize1 = 2\n",
    "# max pooling window size\n",
    "poolingWindowSz = 2\n",
    "# number of filters in fully connected layers\n",
    "numNueronsFCL1 = 128\n",
    "numNueronsFCL2 = 128\n",
    "# split ratio for test and validation\n",
    "trainSplitRatio = 0.8\n",
    "# number of epochs\n",
    "Epochs = 10\n",
    "# batchsize\n",
    "batchSize = 10\n",
    "# number of total clases\n",
    "numClasses = labels.shape[1]\n",
    "# dropout ratio for dropout layer\n",
    "dropOutRatio = 0.2\n",
    "# reshaping the data for network input\n",
    "reshapedSegments = segments.reshape(segments.shape[0], numOfRows, numOfColumns,1)\n",
    "# splitting in training and testing data\n",
    "trainSplit = np.random.rand(len(reshapedSegments)) < trainSplitRatio\n",
    "trainX = reshapedSegments[trainSplit]\n",
    "testX = reshapedSegments[~trainSplit]\n",
    "trainX = np.nan_to_num(trainX)\n",
    "testX = np.nan_to_num(testX)\n",
    "trainY = labels[trainSplit]\n",
    "testY = labels[~trainSplit]\n",
    "\n",
    "def cnnModel():\n",
    "    model = Sequential()\n",
    "    # adding the first convolutionial layer with 32 filters and 5 by 5 kernal size, using the rectifier as the activation function\n",
    "    model.add(Conv2D(numFilters, (kernalSize1,kernalSize1),input_shape=(numOfRows, numOfColumns,1),activation='relu'))\n",
    "    # adding a maxpooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(poolingWindowSz,poolingWindowSz),padding='valid'))\n",
    "    # adding a dropout layer for the regularization and avoiding over fitting\n",
    "    model.add(Dropout(dropOutRatio))\n",
    "    # flattening the output in order to apply the fully connected layer\n",
    "    model.add(Flatten())\n",
    "    # adding first fully connected layer with 256 outputs\n",
    "    model.add(Dense(numNueronsFCL1, activation='relu'))\n",
    "    #adding second fully connected layer 128 outputs\n",
    "    model.add(Dense(numNueronsFCL2, activation='relu'))\n",
    "    # adding softmax layer for the classification\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "    # Compiling the model to generate a model\n",
    "    adam = optimizers.Adam(lr = 0.001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "model = cnnModel()\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "model.fit(trainX,trainY, validation_split=1-trainSplitRatio,epochs=10,batch_size=batchSize,verbose=2)\n",
    "score = model.evaluate(testX,testY,verbose=2)\n",
    "print('Baseline Error: %.2f%%' %(100-score[1]*100))\n",
    "model.save('model.h5')\n",
    "np.save('C://Users/feria/Documents/HAR-CNN-Keras-master/groundTruth.npy',testY)\n",
    "np.save('C://Users/feria/Documents/HAR-CNN-Keras-master/testData.npy',testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
