{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf_text_graph_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4872c5cf350b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_text_graph_common\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreadTextMessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_text_graph_ssd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreateSSDGraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_text_graph_faster_rcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreateFasterRCNNGraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_text_graph_common'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from threading import Thread\n",
    "import asyncio\n",
    "if sys.version_info[0] == 2:\n",
    "    import Queue as queue\n",
    "else:\n",
    "    import queue\n",
    "\n",
    "from common import *\n",
    "from tf_text_graph_common import readTextMessage\n",
    "from tf_text_graph_ssd import createSSDGraph\n",
    "from tf_text_graph_faster_rcnn import createFasterRCNNGraph\n",
    "\n",
    "backends = (cv.dnn.DNN_BACKEND_DEFAULT, cv.dnn.DNN_BACKEND_HALIDE, cv.dnn.DNN_BACKEND_INFERENCE_ENGINE, cv.dnn.DNN_BACKEND_OPENCV)\n",
    "targets = (cv.dnn.DNN_TARGET_CPU, cv.dnn.DNN_TARGET_OPENCL, cv.dnn.DNN_TARGET_OPENCL_FP16, cv.dnn.DNN_TARGET_MYRIAD)\n",
    "\n",
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "parser.add_argument('--zoo', default=os.path.join(os.path.dirname(os.path.abspath(__file__)), 'models.yml'),\n",
    "                    help='An optional path to file with preprocessing parameters.')\n",
    "parser.add_argument('--input', help='Path to input image or video file. Skip this argument to capture frames from a camera.')\n",
    "parser.add_argument('--out_tf_graph', default='graph.pbtxt',\n",
    "                    help='For models from TensorFlow Object Detection API, you may '\n",
    "                         'pass a .config file which was used for training through --config '\n",
    "                         'argument. This way an additional .pbtxt file with TensorFlow graph will be created.')\n",
    "parser.add_argument('--framework', choices=['caffe', 'tensorflow', 'torch', 'darknet', 'dldt'],\n",
    "                    help='Optional name of an origin framework of the model. '\n",
    "                         'Detect it automatically if it does not set.')\n",
    "parser.add_argument('--thr', type=float, default=0.5, help='Confidence threshold')\n",
    "parser.add_argument('--nms', type=float, default=0.4, help='Non-maximum suppression threshold')\n",
    "parser.add_argument('--backend', choices=backends, default=cv.dnn.DNN_BACKEND_DEFAULT, type=int,\n",
    "                    help=\"Choose one of computation backends: \"\n",
    "                         \"%d: automatically (by default), \"\n",
    "                         \"%d: Halide language (http://halide-lang.org/), \"\n",
    "                         \"%d: Intel's Deep Learning Inference Engine (https://software.intel.com/openvino-toolkit), \"\n",
    "                         \"%d: OpenCV implementation\" % backends)\n",
    "parser.add_argument('--target', choices=targets, default=cv.dnn.DNN_TARGET_CPU, type=int,\n",
    "                    help='Choose one of target computation devices: '\n",
    "                         '%d: CPU target (by default), '\n",
    "                         '%d: OpenCL, '\n",
    "                         '%d: OpenCL fp16 (half-float precision), '\n",
    "                         '%d: VPU' % targets)\n",
    "parser.add_argument('--async', type=int, default=0,\n",
    "                    help='Number of asynchronous forwards at the same time. '\n",
    "                         'Choose 0 for synchronous mode')\n",
    "args, _ = parser.parse_known_args()\n",
    "add_preproc_args(args.zoo, parser, 'object_detection')\n",
    "parser = argparse.ArgumentParser(parents=[parser],\n",
    "                                 description='Use this script to run object detection deep learning networks using OpenCV.',\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.model = findFile(args.model)\n",
    "args.config = findFile(args.config)\n",
    "args.classes = findFile(args.classes)\n",
    "\n",
    "# If config specified, try to load it as TensorFlow Object Detection API's pipeline.\n",
    "config = readTextMessage(args.config)\n",
    "if 'model' in config:\n",
    "    print('TensorFlow Object Detection API config detected')\n",
    "    if 'ssd' in config['model'][0]:\n",
    "        print('Preparing text graph representation for SSD model: ' + args.out_tf_graph)\n",
    "        createSSDGraph(args.model, args.config, args.out_tf_graph)\n",
    "        args.config = args.out_tf_graph\n",
    "    elif 'faster_rcnn' in config['model'][0]:\n",
    "        print('Preparing text graph representation for Faster-RCNN model: ' + args.out_tf_graph)\n",
    "        createFasterRCNNGraph(args.model, args.config, args.out_tf_graph)\n",
    "        args.config = args.out_tf_graph\n",
    "\n",
    "\n",
    "# Load names of classes\n",
    "classes = None\n",
    "if args.classes:\n",
    "    with open(args.classes, 'rt') as f:\n",
    "        classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Load a network\n",
    "net = cv.dnn.readNet(cv.samples.findFile(args.model), cv.samples.findFile(args.config), args.framework)\n",
    "net.setPreferableBackend(args.backend)\n",
    "net.setPreferableTarget(args.target)\n",
    "outNames = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "confThreshold = args.thr\n",
    "nmsThreshold = args.nms\n",
    "\n",
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    def drawPred(classId, conf, left, top, right, bottom):\n",
    "        # Draw a bounding box.\n",
    "        cv.rectangle(frame, (left, top), (right, bottom), (0, 255, 0))\n",
    "\n",
    "        label = '%.2f' % conf\n",
    "\n",
    "        # Print a label of class.\n",
    "        if classes:\n",
    "            assert(classId < len(classes))\n",
    "            label = '%s: %s' % (classes[classId], label)\n",
    "\n",
    "        labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        top = max(top, labelSize[1])\n",
    "        cv.rectangle(frame, (left, top - labelSize[1]), (left + labelSize[0], top + baseLine), (255, 255, 255), cv.FILLED)\n",
    "        cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "    layerNames = net.getLayerNames()\n",
    "    lastLayerId = net.getLayerId(layerNames[-1])\n",
    "    lastLayer = net.getLayer(lastLayerId)\n",
    "\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    if lastLayer.type == 'DetectionOutput':\n",
    "        # Network produces output blob with a shape 1x1xNx7 where N is a number of\n",
    "        # detections and an every detection is a vector of values\n",
    "        # [batchId, classId, confidence, left, top, right, bottom]\n",
    "        for out in outs:\n",
    "            for detection in out[0, 0]:\n",
    "                confidence = detection[2]\n",
    "                if confidence > confThreshold:\n",
    "                    left = int(detection[3])\n",
    "                    top = int(detection[4])\n",
    "                    right = int(detection[5])\n",
    "                    bottom = int(detection[6])\n",
    "                    width = right - left + 1\n",
    "                    height = bottom - top + 1\n",
    "                    if width * height <= 1:\n",
    "                        left = int(detection[3] * frameWidth)\n",
    "                        top = int(detection[4] * frameHeight)\n",
    "                        right = int(detection[5] * frameWidth)\n",
    "                        bottom = int(detection[6] * frameHeight)\n",
    "                        width = right - left + 1\n",
    "                        height = bottom - top + 1\n",
    "                    classIds.append(int(detection[1]) - 1)  # Skip background label\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([left, top, width, height])\n",
    "    elif lastLayer.type == 'Region':\n",
    "        # Network produces output blob with a shape NxC where N is a number of\n",
    "        # detected objects and C is a number of classes + 4 where the first 4\n",
    "        # numbers are [center_x, center_y, width, height]\n",
    "        classIds = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                classId = np.argmax(scores)\n",
    "                confidence = scores[classId]\n",
    "                if confidence > confThreshold:\n",
    "                    center_x = int(detection[0] * frameWidth)\n",
    "                    center_y = int(detection[1] * frameHeight)\n",
    "                    width = int(detection[2] * frameWidth)\n",
    "                    height = int(detection[3] * frameHeight)\n",
    "                    left = int(center_x - width / 2)\n",
    "                    top = int(center_y - height / 2)\n",
    "                    classIds.append(classId)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([left, top, width, height])\n",
    "    else:\n",
    "        print('Unknown output layer type: ' + lastLayer.type)\n",
    "        exit()\n",
    "\n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(classIds[i], confidences[i], left, top, left + width, top + height)\n",
    "\n",
    "# Process inputs\n",
    "winName = 'Deep learning object detection in OpenCV'\n",
    "cv.namedWindow(winName, cv.WINDOW_NORMAL)\n",
    "\n",
    "def callback(pos):\n",
    "    global confThreshold\n",
    "    confThreshold = pos / 100.0\n",
    "\n",
    "cv.createTrackbar('Confidence threshold, %', winName, int(confThreshold * 100), 99, callback)\n",
    "\n",
    "cap = cv.VideoCapture(cv.samples.findFileOrKeep(args.input) if args.input else 0)\n",
    "\n",
    "class QueueFPS(queue.Queue):\n",
    "    def __init__(self):\n",
    "        queue.Queue.__init__(self)\n",
    "        self.startTime = 0\n",
    "        self.counter = 0\n",
    "\n",
    "    def put(self, v):\n",
    "        queue.Queue.put(self, v)\n",
    "        self.counter += 1\n",
    "        if self.counter == 1:\n",
    "            self.startTime = time.time()\n",
    "\n",
    "    def getFPS(self):\n",
    "        return self.counter / (time.time() - self.startTime)\n",
    "\n",
    "\n",
    "process = True\n",
    "\n",
    "#\n",
    "# Frames capturing thread\n",
    "#\n",
    "framesQueue = QueueFPS()\n",
    "def framesThreadBody():\n",
    "    global framesQueue, process\n",
    "\n",
    "    while process:\n",
    "        hasFrame, frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "        framesQueue.put(frame)\n",
    "\n",
    "\n",
    "#\n",
    "# Frames processing thread\n",
    "#\n",
    "processedFramesQueue = queue.Queue()\n",
    "predictionsQueue = QueueFPS()\n",
    "def processingThreadBody():\n",
    "    global processedFramesQueue, predictionsQueue, args, process\n",
    "\n",
    "    futureOutputs = []\n",
    "    while process:\n",
    "        # Get a next frame\n",
    "        frame = None\n",
    "        try:\n",
    "            frame = framesQueue.get_nowait()\n",
    "\n",
    "            if (args.asyncio.coroutine):\n",
    "                if len(futureOutputs) == args.asyncio.coroutine:\n",
    "                    frame = None  # Skip the frame\n",
    "            else:\n",
    "                framesQueue.queue.clear()  # Skip the rest of frames\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "\n",
    "\n",
    "        if not frame is None:\n",
    "            frameHeight = frame.shape[0]\n",
    "            frameWidth = frame.shape[1]\n",
    "\n",
    "            # Create a 4D blob from a frame.\n",
    "            inpWidth = args.width if args.width else frameWidth\n",
    "            inpHeight = args.height if args.height else frameHeight\n",
    "            blob = cv.dnn.blobFromImage(frame, size=(inpWidth, inpHeight), swapRB=args.rgb, ddepth=cv.CV_8U)\n",
    "            processedFramesQueue.put(frame)\n",
    "\n",
    "            # Run a model\n",
    "            net.setInput(blob, scalefactor=args.scale, mean=args.mean)\n",
    "            if net.getLayer(0).outputNameToIndex('im_info') != -1:  # Faster-RCNN or R-FCN\n",
    "                frame = cv.resize(frame, (inpWidth, inpHeight))\n",
    "                net.setInput(np.array([[inpHeight, inpWidth, 1.6]], dtype=np.float32), 'im_info')\n",
    "\n",
    "            if (args.asyncio.coroutine):\n",
    "                futureOutputs.append(net.forwardAsync())\n",
    "            else:\n",
    "                outs = net.forward(outNames)\n",
    "                predictionsQueue.put(np.copy(outs))\n",
    "\n",
    "        while futureOutputs and futureOutputs[0].wait_for(0):\n",
    "            out = futureOutputs[0].get()\n",
    "            predictionsQueue.put(np.copy([out]))\n",
    "\n",
    "            del futureOutputs[0]\n",
    "\n",
    "\n",
    "framesThread = Thread(target=framesThreadBody)\n",
    "framesThread.start()\n",
    "\n",
    "processingThread = Thread(target=processingThreadBody)\n",
    "processingThread.start()\n",
    "\n",
    "#\n",
    "# Postprocessing and rendering loop\n",
    "#\n",
    "while cv.waitKey(1) < 0:\n",
    "    try:\n",
    "        # Request prediction first because they put after frames\n",
    "        outs = predictionsQueue.get_nowait()\n",
    "        frame = processedFramesQueue.get_nowait()\n",
    "\n",
    "        postprocess(frame, outs)\n",
    "\n",
    "        # Put efficiency information.\n",
    "        if predictionsQueue.counter > 1:\n",
    "            label = 'Camera: %.2f FPS' % (framesQueue.getFPS())\n",
    "            cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n",
    "\n",
    "            label = 'Network: %.2f FPS' % (predictionsQueue.getFPS())\n",
    "            cv.putText(frame, label, (0, 30), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n",
    "\n",
    "            label = 'Skipped frames: %d' % (framesQueue.counter - predictionsQueue.counter)\n",
    "            cv.putText(frame, label, (0, 45), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))\n",
    "\n",
    "        cv.imshow(winName, frame)\n",
    "    except queue.Empty:\n",
    "        pass\n",
    "\n",
    "\n",
    "process = False\n",
    "framesThread.join()\n",
    "processingThread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
